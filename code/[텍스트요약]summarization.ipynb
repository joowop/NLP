{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cd87745",
   "metadata": {},
   "source": [
    "# 대화 요약 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d7b9f07e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'summary_text': '오랜만에 데이트를 할 생각에 기대하고 있었는데 전화를 안 해서 내일 만나기로 했다.'}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "model_name = \"alaggung/bart-r3f\"\n",
    "max_length = 64\n",
    "dialogue = ['어제 밤에 전화한다더니 왜 전화 안했어ㅜㅜㅜ', '미안 깜빡했어', 'ㅎㅎ 다음에 또 그러면 진짜 삐칠거야! 이따 어디서 볼까? 나 수업 4시에 끝나~~!', '아 맞네 미안 까먹고 친구랑 약속 잡았는데', '뭐야... 오랜만에 데이트 할 생각에 엄청 기대하고 있었는데ㅠㅠㅠㅠ', '미안 까먹고 있었어 진짜 오랜만에 보는 친구여서 그래 이해좀 해주라 우리 데이트는 다음에 하면 되잖아 응?', '진짜 서운하다...', '미안미안 나 이제 다시 수업 들으러 가야겠다 이따 카톡할게', '어디야? 아직도 안끝났어?', '왜 자꾸 전화해 오늘 친구본다고 말했잖아', '너 진짜 너무한거 아니냐? 나만 연애하니? 중간에 연락한번 해줄수도 있는 거잖아! 너 요즘 왜그래?', '아 몰라 쨋든 낼 연락할게 낼 보자', '아냐 그냥 헤어지자 이럴수록 나만 병신같애 이제 우린 끝이야 안녕']\n",
    "summarizer = pipeline(\"summarization\", model=model_name)\n",
    "summarization = summarizer(\"[BOS]\" + \"[SEP]\".join(dialogue) + \"[EOS]\", max_length=max_length)\n",
    "\n",
    "print(summarization)\n",
    "# Your max_length is set to 64, but you input_length is only 51. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=25)\n",
    "# [{'summary_text': '어제 김치찌개를 먹어서 한식 말고 돈가스를 먹기로 했다.'}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eadba826",
   "metadata": {},
   "source": [
    "# 파라미터 수정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "01a0e791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오랜만에 데이트를 할 생각에 기대하고 있었는데 오랜만에 보는 친구여서 서운하다고 하니 중간에 연락을 한 번 해줄 수도 있으니 헤어지자고 한다.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, BartForConditionalGeneration\n",
    "\n",
    "model_name = \"alaggung/bart-r3f\"\n",
    "# 요약이 이 길이를 초과하면 지정된 제한에 맞게 잘립니다.\n",
    "max_length = 50\n",
    "# num_beams 값을 늘리면 요약이 더 다양해지지만 잠재적으로 덜 정확할 수 있으며 값을 줄이면 요약이 더 집중되지만 덜 다양해집니다.\n",
    "num_beams = 5\n",
    "# length_penalty 값이 높을수록 모델이 더 긴 요약을 생성하도록 하고 값이 낮을수록 더 짧은 요약을 생성합니다.\n",
    "length_penalty = 1.2\n",
    "repetition_penalty = 0.8\n",
    "temperature  = 1.0\n",
    "\n",
    "dialogue = ['어제 밤에 전화한다더니 왜 전화 안했어ㅜㅜㅜ', '미안 깜빡했어', 'ㅎㅎ 다음에 또 그러면 진짜 삐칠거야! 이따 어디서 볼까? 나 수업 4시에 끝나~~!', '아 맞네 미안 까먹고 친구랑 약속 잡았는데', '뭐야... 오랜만에 데이트 할 생각에 엄청 기대하고 있었는데ㅠㅠㅠㅠ', '미안 까먹고 있었어 진짜 오랜만에 보는 친구여서 그래 이해좀 해주라 우리 데이트는 다음에 하면 되잖아 응?', '진짜 서운하다...', '미안미안 나 이제 다시 수업 들으러 가야겠다 이따 카톡할게', '어디야? 아직도 안끝났어?', '왜 자꾸 전화해 오늘 친구본다고 말했잖아', '너 진짜 너무한거 아니냐? 나만 연애하니? 중간에 연락한번 해줄수도 있는 거잖아! 너 요즘 왜그래?', '아 몰라 쨋든 낼 연락할게 낼 보자', '아냐 그냥 헤어지자 이럴수록 나만 병신같애 이제 우린 끝이야 안녕']\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = BartForConditionalGeneration.from_pretrained(model_name)\n",
    "model.eval()\n",
    "\n",
    "inputs = tokenizer(\"[BOS]\" + \"[SEP]\".join(dialogue) + \"[EOS]\", return_tensors=\"pt\")\n",
    "outputs = model.generate(\n",
    "    inputs.input_ids,\n",
    "    attention_mask=inputs.attention_mask,\n",
    "    num_beams=num_beams,\n",
    "    length_penalty=length_penalty,\n",
    "    max_length=max_length,\n",
    "    repetition_penalty = repetition_penalty,\n",
    "    temperature = temperature ,\n",
    "    use_cache=True,\n",
    ")\n",
    "summarization = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "print(summarization)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c7e62d7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'어제 밤에 전화한다더니 왜 전화 안했어ㅜㅜㅜ 미안 깜빡했어 ㅎㅎ 다음에 또 그러면 진짜 삐칠거야! 이따 어디서 볼까? 나 수업 4시에 끝나~~! 아 맞네 미안 까먹고 친구랑 약속 잡았는데 뭐야... 오랜만에 데이트 할 생각에 엄청 기대하고 있었는데ㅠㅠㅠㅠ 미안 까먹고 있었어 진짜 오랜만에 보는 친구여서 그래 이해좀 해주라 우리 데이트는 다음에 하면 되잖아 응? 진짜 서운하다... 미안미안 나 이제 다시 수업 들으러 가야겠다 이따 카톡할게 어디야? 아직도 안끝났어? 왜 자꾸 전화해 오늘 친구본다고 말했잖아 너 진짜 너무한거 아니냐? 나만 연애하니? 중간에 연락한번 해줄수도 있는 거잖아! 너 요즘 왜그래? 아 몰라 쨋든 낼 연락할게 낼 보자 아냐 그냥 헤어지자 이럴수록 나만 병신같애 이제 우린 끝이야 안녕'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = ['어제 밤에 전화한다더니 왜 전화 안했어ㅜㅜㅜ', '미안 깜빡했어', 'ㅎㅎ 다음에 또 그러면 진짜 삐칠거야! 이따 어디서 볼까? 나 수업 4시에 끝나~~!', '아 맞네 미안 까먹고 친구랑 약속 잡았는데', '뭐야... 오랜만에 데이트 할 생각에 엄청 기대하고 있었는데ㅠㅠㅠㅠ', '미안 까먹고 있었어 진짜 오랜만에 보는 친구여서 그래 이해좀 해주라 우리 데이트는 다음에 하면 되잖아 응?', '진짜 서운하다...', '미안미안 나 이제 다시 수업 들으러 가야겠다 이따 카톡할게', '어디야? 아직도 안끝났어?', '왜 자꾸 전화해 오늘 친구본다고 말했잖아', '너 진짜 너무한거 아니냐? 나만 연애하니? 중간에 연락한번 해줄수도 있는 거잖아! 너 요즘 왜그래?', '아 몰라 쨋든 낼 연락할게 낼 보자', '아냐 그냥 헤어지자 이럴수록 나만 병신같애 이제 우린 끝이야 안녕']\n",
    "' '.join(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ff227a",
   "metadata": {},
   "source": [
    "# lcw99/t5-base-korean-text-summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f981cb",
   "metadata": {},
   "source": [
    "# 텍스트 요약 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "48300281",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오랜만에 보는 친구라서 이해좀 해주라 우리 데이트는 다음에 하면 되잖아 응?\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "model_dir = \"lcw99/t5-base-korean-text-summary\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_dir)\n",
    "\n",
    "max_input_length = 512\n",
    "\n",
    "# text = \"\"\"안녕하세요 PM 취준 희망하는데요 혹시 ADsP 자격증이 있으면 취업때 유리할까요..? SQLD도 의미잇는지 궁금하고요! 현재 사이드프로젝트도 하고 있는데 정량적인 스펙을 좀 쌓고 싶어서 여쭙니다! 아뇨....... ADSP..진짜 하나도 도움 X SQLD도 있으나 마나... 취업에 유리하다고 보긴 어렵고 취업에 도움이 되는 포폴 만드는데 도움이 되죠 그래도 이력서볼때 서류통과에는 조금 낫지않아요?? 없는 것보단요 ㅋㅋ 그저 실력보단 성실도의 측면으로료ㅋㅋ 없는 것보단 있는게 낫지 않을까요 만약에 전사적으로 데이터를 볼 수 있는 데이터 웨어하우스가 잘 구축되어있고, 누구나 SQL을 통해서 데이터를 볼 수 있는 환경이라면 쿼리를 작성할 줄 안다는건 이점이 되지 않을까요? PM은 보통 어떻게 사이드 프로젝트를 하시나요?? 저는 데분을 꿈꾸눈데 궁금해서요 자격증은 그자체로 의미를 갖기보다 과정에서 나오는 성실성과 노력을 표현하는 거라고 생각해요~. PM 준비하셔도  충분히 도움이 되는 내용이니 공부하시면 스스로 성장에 도움이 됩니다. 최근 발달한 조직에서는 PM, 마케팅단에서 직접 sql 쿼리 추출하고 대시보드로 그 업무를 직접 수행하기도하니 있으면 손해볼일은 없죠~ 저도 취준이라면 공부해서 자격증 취득하는게 좋을거 같습니다. 약간의 공부 자기만족 이력서 한줄 이정도면 뭐.. 나쁘지 않다고 봅니다 혹시 토스 인턴 결과 아직 다 안나오셨죠?? 진짜 하나도 도움x 인정 ADsP SQLD 같은 자격증은 가산점 준다고 딱 명시하지 않는 이상은 도움이 되는 거 같지는 않더라고요.. 관심이 있으니 공부해서 따기는 했구나 정도로는 생각하시는 거 같았습니다. 데이터 분석가로 일하는 분들 중에도 없는 분들도 있는 거 같더라구요. 저도 해당 자격증들이 업무에 도움이 되지는 않았다고 생각하지만 sqld, adsp, 빅분기 모두 따놨던 게 결국 최종 합격 때 도움이 됐었어요 자격증 세 개 따면서 어느정도 공부는 했구나, 이 분야에 관심이 있었구나 해서 다른 신입이랑 비교해서 정량평가할 때 자격증 있는 사람으로 1차 필터링 했다고 하셨어요 맞아요 신입땐 유리해요~ 다른 강조할게 없으시면 따셔요 이건 제가 준비중이라 궁금해서 그러는데 sqld adsp 말고 빅분기는 취준에게 좀 도움이 되나요? 그래두 기사 자격증인뎅.,,, 특히 직무 전환하시는분들도요 오.. 요즘엔 자격증 따는 사람들이 많아서 필터링 할 수도 있겠네요 마치 토익같아요 ㅋㅋㅋ맞아요 넘 흔하죠 ㅋㅋ sqld는 기본이고 실력도 대변하지않고요 ㅋㅋ adsp는 굳이 싶고 실무에서는 전혀 쓸일 없으십니다 빅분기는 따면 오 그래도 공부는 했구나 싶죠모 ㅋㅋㅋㅋ 마자요 근데 진짜암것도없는데 포폴도 뻔하다 통계나 모델 이야기 할 때 어느정도 알아듣겠다 정도 인식이 있을 것 같아요 이러면... 좀 그렇죠 불리해요 빅분기는 1년에 2번따기 때문에 부지런이 따놓으면 경쟁자를 이길수(?) 있음 실무에 도움된다허시면 차라리 앰플리튜드나 ga같은 프로덕트 분석툴을 연마하시는편이 좋으실거같네요 이게 자격증 시험이 시험 합격에 초점을 맞춰서 그렇지 개념이나 기초들은 충분히 도움이 됩니다.  다들 깊게 공부보다는 합격만하기 위한 방법을 써왔고, 그게 평가자 입장에서도 공감이 되니 취업 시장에서는 변별력을 잃는 것 같아요  제 생각입니다 잘 모르는 평가자라면 자격증 +1이 도움이 될 수도 있어요 우왓 자세하고 꼼꼼한 답변... 너무너무 감사합니다아! 취준생에게 너무 큰 조언이네요.. \\U0001f979\\U0001fa77\"\"\"\n",
    "text = '''어제 밤에 전화한다더니 왜 전화 안했어ㅜㅜㅜ 미안 깜빡했어 ㅎㅎ 다음에 또 그러면 진짜 삐칠거야! 이따 어디서 볼까? 나 수업 4시에 끝나~~! 아 맞네 미안 까먹고 친구랑 약속 잡았는데 뭐야... 오랜만에 데이트 할 생각에 엄청 기대하고 있었는데ㅠㅠㅠㅠ 미안 까먹고 있었어 진짜 오랜만에 보는 친구여서 그래 이해좀 해주라 우리 데이트는 다음에 하면 되잖아 응? 진짜 서운하다... 미안미안 나 이제 다시 수업 들으러 가야겠다 이따 카톡할게 어디야? 아직도 안끝났어? 왜 자꾸 전화해 오늘 친구본다고 말했잖아 너 진짜 너무한거 아니냐? 나만 연애하니? 중간에 연락한번 해줄수도 있는 거잖아! 너 요즘 왜그래? 아 몰라 쨋든 낼 연락할게 낼 보자 아냐 그냥 헤어지자 이럴수록 나만 병신같애 이제 우린 끝이야 안녕'''\n",
    "inputs = [\"summarize: \" + text]\n",
    "\n",
    "inputs = tokenizer(inputs, max_length=max_input_length, truncation=True, return_tensors=\"pt\")\n",
    "output = model.generate(**inputs, num_beams=8, do_sample=True, min_length=10, max_length=150)\n",
    "decoded_output = tokenizer.batch_decode(output, skip_special_tokens=True)[0]\n",
    "predicted_title = nltk.sent_tokenize(decoded_output.strip())[0]\n",
    "\n",
    "print(predicted_title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc1a7f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
