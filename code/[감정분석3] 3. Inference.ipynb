{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dad1d421",
   "metadata": {},
   "source": [
    "# **Settings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5ca2314e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')                       # warning 출력 false\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834e93f4",
   "metadata": {},
   "source": [
    "# **1. Model Settings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "710d6768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downstream_model_checkpoint_fpath: ./kcbert2\\epoch=5-val_loss=0.01.ckpt\n"
     ]
    }
   ],
   "source": [
    "from ratsnlp.nlpbook.classification import ClassificationDeployArguments\n",
    "\n",
    "# model setting\n",
    "model_path = './kcbert3'\n",
    "\n",
    "# arguments\n",
    "args = ClassificationDeployArguments(\n",
    "    pretrained_model_name = 'beomi/kcbert-base',\n",
    "    downstream_model_dir = model_path,\n",
    "    max_seq_length = 128\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e35dd9",
   "metadata": {},
   "source": [
    "# **2. Tokenizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e46f9b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\n",
    "    args.pretrained_model_name,\n",
    "    do_lower_case = False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8f1c7b",
   "metadata": {},
   "source": [
    "# **3. Load Checkpoint**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4a1f9e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load checkpoint\n",
    "import torch\n",
    "fine_tuned_model_ckpt = torch.load(\n",
    "    args.downstream_model_checkpoint_fpath,\n",
    "    map_location=torch.device('cpu')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0818b0a7",
   "metadata": {},
   "source": [
    "# **4. Model Config**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "83895c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertConfig, BertForSequenceClassification\n",
    "\n",
    "# 모델 생성 및 초기화\n",
    "from transformers import BertConfig\n",
    "pretrained_model_config = BertConfig.from_pretrained(\n",
    "    args.pretrained_model_name,\n",
    "    num_labels = fine_tuned_model_ckpt['state_dict']['model.classifier.bias'].shape.numel()\n",
    ")\n",
    "\n",
    "model = BertForSequenceClassification(pretrained_model_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4b5d43",
   "metadata": {},
   "source": [
    "# **5. Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a4ed2991",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30000, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(300, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=7, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 불러오기\n",
    "model.load_state_dict({k.replace('model.',''): v for k,v in fine_tuned_model_ckpt['state_dict'].items()})\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53616ce9",
   "metadata": {},
   "source": [
    "# 6. Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40883f91",
   "metadata": {},
   "source": [
    "## **1) 감정 정보**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "29b1ca69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(453965, 4) (56248, 4)\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv('./data3/train_data.csv')\n",
    "val_data = pd.read_csv('./data3/val_data.csv')\n",
    "print(train_data.shape, val_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "73d8f20b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Happy: ['고맙다' '굉장하다' '만족스럽다' '뭉클하다' '반갑다' '부유하다' '사랑스럽다' '영광스럽다' '자랑스럽다' '자유롭다'\n",
      " '즐겁다' '행복하다' '홀가분하다' '화목하다' '흐뭇하다']\n",
      "Sad: ['가엾다' '괴롭다' '그립다' '보잘것없다' '불쌍하다' '불행하다' '뼈아프다' '서럽다' '시무룩하다' '쓸쓸하다' '아쉽다'\n",
      " '안타깝다' '억울하다']\n",
      "Angry: ['경멸스럽다' '기막히다' '끔찍하다' '무례하다' '밉다' '배은망덕하다' '부당하다' '뻔뻔스럽다' '아니꼽다' '악랄하다'\n",
      " '억울하다' '언짢다' '짜증스럽다' '치욕스럽다' '한심하다']\n",
      "Anxious: ['갑갑하다' '고통스럽다' '꺼림칙하다' '다급하다' '두렵다' '불확실하다' '수상하다' '심란하다' '아득하다' '약하다'\n",
      " '외롭다' '위험하다' '의심스럽다' '조마조마하다' '혼란하다']\n",
      "Hurt: ['고통스럽다' '괴롭다' '냉정하다' '매정하다' '못되다' '무관심하다' '밉다' '불행하다' '뼈아프다' '서럽다' '섭섭하다'\n",
      " '슬프다' '쓰리다']\n",
      "Embarrassed: ['갑작스럽다' '곤란하다' '급하다' '기막히다' '난데없다' '남사스럽다' '망하다' '버겁다' '부끄럽다' '아찔하다'\n",
      " '어리둥절하다' '엉뚱하다' '창피하다' '혼란하다']\n",
      "Neutrality: ['긴밀하다' '녹녹하다' '담백하다' '대동소이하다' '둥그스름하다' '뚜렷하다' '얕다' '어렴풋하다' '엄밀하다' '엄중하다'\n",
      " '예사롭다' '자세하다']\n"
     ]
    }
   ],
   "source": [
    "train_data['emotion'].unique()\n",
    "\n",
    "for emotion in train_data['emotion'].unique():\n",
    "    sub_emotion = train_data[train_data['emotion']==emotion]['sensitivity'].unique()\n",
    "    print(f'{emotion}: {sub_emotion}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3e183f16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Angry', 'Anxious', 'Embarrassed', 'Happy', 'Hurt', 'Neutrality',\n",
       "       'Sad'], dtype=object)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "with open('./data2/encoder.pkl', 'rb') as f:\n",
    "    encoder = pickle.load(f)\n",
    "encoder.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b692b1",
   "metadata": {},
   "source": [
    "## **2) 노래가사 감정 추론**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "58dc6dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추론\n",
    "def inference_fn(sentence):\n",
    "    emotion_list = ['분노', '불안', '당황', '기쁨', '상처', '중립','슬픔']\n",
    "    inputs = tokenizer(\n",
    "        [sentence],\n",
    "        max_length=args.max_seq_length,\n",
    "        padding = 'max_length',\n",
    "        truncation=True\n",
    "    )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**{k: torch.tensor(v) for k,v in inputs.items()})\n",
    "        prob = outputs.logits.softmax(dim=1)\n",
    "        positive_prob = round(prob[0][1].item(),4)\n",
    "        negative_prob = round(prob[0][0].item(),4)\n",
    "        pred = torch.argmax(prob).item()\n",
    "        \n",
    "        return emotion_list[pred]\n",
    "    \n",
    "# 추론\n",
    "def lyrics_preprocessing(lyrics):\n",
    "    lyrics = re.sub('[^ㄱ-ㅣ가-힣]',' ',lyrics).split('  ')\n",
    "    lyrics = [x .strip() for x in lyrics if x != '']\n",
    "    lyrics = ' '.join(list(set(lyrics)))\n",
    "    \n",
    "    return lyrics\n",
    "\n",
    "def inference_fn_lyrics(lyrics):\n",
    "    emotion_list = ['분노', '불안', '당황', '기쁨', '상처', '중립','슬픔']\n",
    "    \n",
    "    sentence = lyrics_preprocessing(lyrics)\n",
    "    if len(sentence) == 0:\n",
    "        return 'X'\n",
    "    \n",
    "    inputs = tokenizer(\n",
    "        [sentence],\n",
    "        max_length=args.max_seq_length,\n",
    "        padding = 'max_length',\n",
    "        truncation=True\n",
    "    )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**{k: torch.tensor(v) for k,v in inputs.items()})\n",
    "        prob = outputs.logits.softmax(dim=1)\n",
    "        pred = torch.argmax(prob).item()\n",
    "        \n",
    "        return emotion_list[pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "dc43e041",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>분류키워드</th>\n",
       "      <th>가수</th>\n",
       "      <th>곡</th>\n",
       "      <th>장르</th>\n",
       "      <th>가사</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>기분전환</td>\n",
       "      <td>BIGBANG (빅뱅)</td>\n",
       "      <td>거짓말</td>\n",
       "      <td>댄스</td>\n",
       "      <td>ye love is pain to all my brokenhearted people...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>기분전환</td>\n",
       "      <td>소녀시대 (GIRLS' GENERATION)</td>\n",
       "      <td>Gee</td>\n",
       "      <td>댄스</td>\n",
       "      <td>Uh Huh Listen Boy My First Love Story My Angel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>기분전환</td>\n",
       "      <td>원더걸스</td>\n",
       "      <td>Tell me (Sampling From 'Two Of Hearts')</td>\n",
       "      <td>댄스</td>\n",
       "      <td>너도 날 좋아할 줄은 몰랐어 어쩌면 좋아 너무나 좋아 꿈만 같아서 나 내 자신을 자...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>기분전환</td>\n",
       "      <td>2NE1</td>\n",
       "      <td>내가 제일 잘 나가</td>\n",
       "      <td>댄스</td>\n",
       "      <td>내가 제일 잘 나가 내가 제일 잘 나가 내가 제일 잘 나가 내가 제일 잘 나가 제 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>기분전환</td>\n",
       "      <td>미쓰에이</td>\n",
       "      <td>Bad Girl Good Girl</td>\n",
       "      <td>댄스</td>\n",
       "      <td>You don't know me  You don't know me  You don'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4680</th>\n",
       "      <td>한강</td>\n",
       "      <td>죠지</td>\n",
       "      <td>somuch</td>\n",
       "      <td>R&amp;B/Soul</td>\n",
       "      <td>Oh my god 어떻게 우리가 만나서 얼마나 행복해 I feel real happ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4681</th>\n",
       "      <td>한강</td>\n",
       "      <td>죠지</td>\n",
       "      <td>하루종일</td>\n",
       "      <td>R&amp;B/Soul</td>\n",
       "      <td>평소 같은 날들과 할 일 없는 나의 인생 그의 사이로 네가 들어와 줬음 싶어 할일없...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4682</th>\n",
       "      <td>한강</td>\n",
       "      <td>Red House</td>\n",
       "      <td>냉정과 열정 사이 (Feat. slchld)</td>\n",
       "      <td>R&amp;B/Soul</td>\n",
       "      <td>I just tell you mine but It ain’t 화장대 위에 먼지를 닦...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4683</th>\n",
       "      <td>한강</td>\n",
       "      <td>릴러말즈 (Leellamarz)</td>\n",
       "      <td>Number (Feat. BIG Naughty (서동현))</td>\n",
       "      <td>R&amp;B/Soul</td>\n",
       "      <td>오래 기다렸니 나도 기다렸는데 물어보고 싶은 게 300개가 넘네 그러니까 언제든 C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4684</th>\n",
       "      <td>한강</td>\n",
       "      <td>TRADE L</td>\n",
       "      <td>흔들리지 않아 (Feat. 폴킴)</td>\n",
       "      <td>R&amp;B/Soul</td>\n",
       "      <td>이젠 흔들리지 않아 애매한 행동을 했지 너는 어떤 표정을 지을지 궁금해 나빠 내가 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4685 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     분류키워드                        가수                                        곡  \\\n",
       "0     기분전환              BIGBANG (빅뱅)                                      거짓말   \n",
       "1     기분전환  소녀시대 (GIRLS' GENERATION)                                      Gee   \n",
       "2     기분전환                      원더걸스  Tell me (Sampling From 'Two Of Hearts')   \n",
       "3     기분전환                      2NE1                               내가 제일 잘 나가   \n",
       "4     기분전환                      미쓰에이                       Bad Girl Good Girl   \n",
       "...    ...                       ...                                      ...   \n",
       "4680    한강                        죠지                                   somuch   \n",
       "4681    한강                        죠지                                     하루종일   \n",
       "4682    한강                 Red House                 냉정과 열정 사이 (Feat. slchld)   \n",
       "4683    한강         릴러말즈 (Leellamarz)         Number (Feat. BIG Naughty (서동현))   \n",
       "4684    한강                   TRADE L                       흔들리지 않아 (Feat. 폴킴)   \n",
       "\n",
       "            장르                                                 가사  \n",
       "0           댄스  ye love is pain to all my brokenhearted people...  \n",
       "1           댄스  Uh Huh Listen Boy My First Love Story My Angel...  \n",
       "2           댄스  너도 날 좋아할 줄은 몰랐어 어쩌면 좋아 너무나 좋아 꿈만 같아서 나 내 자신을 자...  \n",
       "3           댄스  내가 제일 잘 나가 내가 제일 잘 나가 내가 제일 잘 나가 내가 제일 잘 나가 제 ...  \n",
       "4           댄스  You don't know me  You don't know me  You don'...  \n",
       "...        ...                                                ...  \n",
       "4680  R&B/Soul  Oh my god 어떻게 우리가 만나서 얼마나 행복해 I feel real happ...  \n",
       "4681  R&B/Soul  평소 같은 날들과 할 일 없는 나의 인생 그의 사이로 네가 들어와 줬음 싶어 할일없...  \n",
       "4682  R&B/Soul  I just tell you mine but It ain’t 화장대 위에 먼지를 닦...  \n",
       "4683  R&B/Soul  오래 기다렸니 나도 기다렸는데 물어보고 싶은 게 300개가 넘네 그러니까 언제든 C...  \n",
       "4684  R&B/Soul  이젠 흔들리지 않아 애매한 행동을 했지 너는 어떤 표정을 지을지 궁금해 나빠 내가 ...  \n",
       "\n",
       "[4685 rows x 5 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song_data = pd.read_excel('./result_songDB.xlsx')\n",
    "song_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92d4745",
   "metadata": {},
   "outputs": [],
   "source": [
    "song_data['감정'] = song_data['가사'].apply(lambda x: inference_fn_lyrics(x))\n",
    "song_data = song_data[song_data['감정']!='X']\n",
    "print(song_data.shape)\n",
    "song_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b111b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 저장\n",
    "song_data.to_csv('./songDB_add3.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f145e55b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "828\n",
      "[경북 경산시-김승민]의 감정은 슬픔입니다.\n",
      "0\n",
      "[Changes-Hayd]의 감정은 분노입니다.\n",
      "240\n",
      "[ONCE AGAIN-윈터 (WINTER), 닝닝 (NINGNING)]의 감정은 슬픔입니다.\n",
      "707\n",
      "[할 수 있어-엔알지 (NRG)]의 감정은 상처입니다.\n",
      "532\n",
      "[사랑할 수 없는 너에게-도영 (DOYOUNG)]의 감정은 슬픔입니다.\n",
      "272\n",
      "[1,2,3,4 (원,투,쓰리,포)-이하이]의 감정은 슬픔입니다.\n",
      "426\n",
      "[삐삐-아이유]의 감정은 상처입니다.\n",
      "471\n",
      "[여자는 말 못하고, 남자는 모르는 것들-정동하]의 감정은 분노입니다.\n",
      "363\n",
      "[천애고독 (天涯孤獨)-OoOo (오넷)]의 감정은 슬픔입니다.\n",
      "0\n",
      "[So Good (Stripped)-Halsey]의 감정은 분노입니다.\n",
      "0\n",
      "[Straight Line-Kryga]의 감정은 분노입니다.\n",
      "685\n",
      "[오늘 취하면 (Feat. 창모) (Prod. SUGA)-SURAN (수란)]의 감정은 슬픔입니다.\n",
      "782\n",
      "[남자 없이 잘 살아-미쓰에이]의 감정은 상처입니다.\n",
      "447\n",
      "[나 혼자서-티파니 (TIFFANY)]의 감정은 슬픔입니다.\n",
      "400\n",
      "[감사-김동률]의 감정은 기쁨입니다.\n",
      "525\n",
      "[마법소녀 (魔法少女)-오렌지 캬라멜]의 감정은 기쁨입니다.\n",
      "515\n",
      "[가슴소리-THERAY]의 감정은 상처입니다.\n",
      "503\n",
      "[넌 나의 우주-스무살]의 감정은 기쁨입니다.\n",
      "0\n",
      "[Hate Everything-지소울 (GSoul)]의 감정은 분노입니다.\n",
      "370\n",
      "[The Way U Are-동방신기 (TVXQ!)]의 감정은 분노입니다.\n"
     ]
    }
   ],
   "source": [
    "# 랜덤으로 확인하기\n",
    "n = 20\n",
    "rand_idx = np.random.randint(0,song_data.shape[0],n)\n",
    "\n",
    "for idx in rand_idx:\n",
    "    singer = song_data.iloc[idx,2]\n",
    "    song = song_data.iloc[idx,1]\n",
    "    lyrics = song_data.iloc[idx,4]\n",
    "    emotion = inference_fn_lyrics(lyrics)\n",
    "    print(f'[{singer}-{song}]의 감정은 {emotion}입니다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8cf244bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'슬픔'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference_fn('나랑 다이소 갈 사람')#??????????????????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7dc30d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
